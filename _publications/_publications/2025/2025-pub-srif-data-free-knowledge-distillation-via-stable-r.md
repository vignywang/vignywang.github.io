---
title:          "SRIF: Data-Free Knowledge Distillation via Stable Regulation and Input Filtering"
date:           2025-02-15 00:01:00 +0800
selected:       false
pub:            "IEEE Transactions on Multimedia"
pub_last:       ' <span class="badge badge-pill badge-custom badge-dark">Scholar Paper</span>'
pub_date:       "2025"

abstract: >-
  Data-free knowledge distillation (DFKD) enables knowledge transfer from a pre-trained teacher to a student network without accessing the real dataset. However, generator-based DFKD methods struggle to ensure that the synthetic images accurately reflect the real dataset distribution. The update of the generator network relies heavily on teacher category guidance, but varying teacher prediction accuracy across categories leads to inconsistent synthetic image quality. Such variations introduce a distribution shift between synthetic and real datasets, negatively impacting student network performance during knowledge distillation. To address this challenge, we propose the SRIF, comprising two components: Student-Driven Flexible Filtering (SDFF) and Re-weighting for Independent Regularization (RIR). SDFF filters out synthetic images affected by the category distribution shift during data generation, producing a â€¦

cover:          assets/images/covers/default.png
authors:
  - Zherui Zhang
  - Rongtao Xu
  - Changwei Wang
  - Shibiao Xu
  - Jie Zhou
  - Wenhao Xu
  - Longxiang Gao
  - Wenbo Xu
  - Li Guo
links:
  Paper: https://ieeexplore.ieee.org/abstract/document/11006499/
---
