---
title:          "Controllable Panoramic Video Generation with 360-Degree Motion Consistency"
date:           2026-02-01 00:01:00 +0800
selected:       false
pub:            "Available at SSRN 5433210"
pub_last:       ' <span class="badge badge-pill badge-custom badge-dark">Scholar Paper</span>'
pub_date:       "2026"

abstract: >-
  Generating high-fidelity panoramic videos with seamless spatial and tempo-ral coherence from diverse control signals—such as fragmented narrow field-of-view(NFoV) video clips or static panoramic images—remains a major challenge in intelligent video generation. In this paper, we propose Omni-Pano, a panoramic video synthesis framework based on a masked diffusion transformer (a type of generative model), which enables controllable video generation under multiple input modalities. From an artificial intelligence perspective, our contributions include:(1) a multi-condition training paradigm using five strategic masking schemes to support text-to-video, image-to-video, and NFoV-to-panorama extrapolation tasks in a unified architecture;(2) two novel loss functions—Latitude-Aware Gradient Loss and Frequency-Aware Detail Loss—for improving motion con-tinuity and texture fidelity in latent space; and (3) a boundary restoration method called Phase-shift Spatio Consistency Inpainting, which resolves ar-tifacts typical of equirectangular projections without impairing motion dy-namics. From an engineering application standpoint, OmniPano facilitates the ef-ficient generation of immersive 360-degree content, with potential use cases in virtual reality, simulation systems, education, and panoramic media pro-duction. Extensive experiments demonstrate that our method produces high-quality panoramic videos with superior motion consistency and visual fidelity. The dataset and code will be made publicly available to support reproducibil-ity.(Project: bit. ly/OmniPano)

cover:          assets/images/covers/default.png
authors:
  - YuZhi Chen
  - Muyang Zhang
  - Qi Zeng
  - Leilei Fan
  - Rongtao Xu
  - Changwei Wang
  - Mingming Yu
  - Yanchao Liu
  - Xiaofan Li
  - Weiliang Meng
links:
  Paper: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5433210
---
