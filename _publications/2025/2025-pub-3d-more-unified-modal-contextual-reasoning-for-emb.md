---
title:          "3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering"
date:           2025-01-01 00:01:00 +0800
selected:       false
pub:            "IROS 2025"
pub_last:       ' <span class="badge badge-pill badge-custom badge-dark">Scholar Paper</span>'
pub_date:       "2025"

abstract: >-
  With the growing need for diverse and scalable data in indoor scene tasks, such as question answering and dense captioning, we propose 3D-MoRe, a novel paradigm designed to generate large-scale 3D-language datasets by lever-aging the strengths of foundational models. The framework integrates key components, including multi-modal embedding, cross-modal interaction, and a language model decoder, to process natural language instructions and 3D scene data. This approach facilitates enhanced reasoning and response generation in complex 3D environments. Using the ScanNet 3D scene dataset, along with text annotations from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs and 73,000 object descriptions across 1,513 scenes. We also employ various data augmentation techniques and implement semantic filtering to ensure high-quality data. Experiments on â€¦

cover:          assets/images/covers/default.png
authors:
  - Rongtao Xu
  - Han Gao
  - Mingming Yu
  - Dong An
  - Shunpeng Chen
  - Changwei Wang
  - Li Guo
  - Xiaodan Liang
  - Shibiao Xu
links:
  Paper: https://ieeexplore.ieee.org/abstract/document/11247159/
---
