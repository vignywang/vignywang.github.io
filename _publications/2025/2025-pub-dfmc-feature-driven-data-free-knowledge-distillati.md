---
title:          "Dfmc: feature-driven data-free knowledge distillation"
date:           2025-01-01 00:01:00 +0800
selected:       false
pub:            "IEEE Transactions on Circuits and Systems for Video Technology"
pub_last:       ' <span class="badge badge-pill badge-custom badge-dark">Scholar Paper</span>'
pub_date:       "2025"

abstract: >-
  Data-Free Knowledge Distillation (DFKD) enables knowledge transfer from teacher networks without access to the real dataset. However, generator-based DFKD methods often suffer from insufficient diversity or low-confidence in synthetic images, negatively impacting student network performance. This paper introduces DFMC, a generative feature-driven framework to mitigate the inherent limitations of DFKD. We propose exploiting semantic description between generative feature domains to guide augmentation strategies, avoiding random abstract inputs caused by inconsistent semantic quality. Then, by applying noise to the generative features, we produce contrastive learning pairs indirectly, limiting the sampling range of the feature domain to encourage the student network to learn domain-invariant features. Finally, we guide the student network to deeply mimic the teacher’s layer-wise implicit classification …

cover:          assets/images/covers/default.png
authors:
  - Zherui Zhang
  - Rongtao Xu
  - Changwei Wang
  - Wenhao Xu
  - Shunpeng Chen
  - Shibiao Xu
  - Guangyuan Xu
  - Li Guo
links:
  Paper: https://ieeexplore.ieee.org/abstract/document/10980222/
---
